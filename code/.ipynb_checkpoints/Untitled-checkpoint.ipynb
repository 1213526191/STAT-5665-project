{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.15 |Anaconda, Inc.| (default, Nov 13 2018, 17:07:45) \\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name get_uid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a6c7470eca9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# from keras.models import Sequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# from keras.layers import Dense, Activation, LSTM, Dropout,Conv1D,MaxPooling1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/py2/lib/python2.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/py2/lib/python2.7/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_uid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_dim_ordering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name get_uid"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "from gensim.models.deprecated.doc2vec import LabeledSentence\n",
    "LabeledSentence = LabeledSentence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#import re\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, LSTM, Dropout,Conv1D,MaxPooling1D\n",
    "# from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(corpus):\n",
    "    #corpus = [re.sub('[^a-zA-Z]',' ',z) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "def getlabel(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model[z[1]]).reshape((1, size)) for z in corpus]\n",
    "    #if vecs == 0:\n",
    "    #    vecs = np.zeros([1,size])\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "y_pred = np.array(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    if i<9:\n",
    "        j = (i+1)*100000\n",
    "    else:\n",
    "        j = 16664+(i+1)*100000\n",
    "        \n",
    "    train = pd.read_csv('train_final2.csv')\n",
    "    train = train.sample(700000,random_state=1)\n",
    "    train['date'] = scale(train['date'])\n",
    "    \n",
    "        \n",
    "    test = pd.read_csv('test_final2.csv')\n",
    "    test = test[(100000*i):j]\n",
    "    test['date'] = scale(test['date'])\n",
    "       \n",
    "    x_train = cleanText(list(train['text']))\n",
    "    ntrain = train.shape[0]\n",
    "    x_test = cleanText(list(test['text']))\n",
    "    ntest = test.shape[0]\n",
    "    \n",
    "    x_all = getlabel(x_train, 'TRAIN')\n",
    "    del x_train\n",
    "    x_test = getlabel(x_test, 'TEST')\n",
    "    x_all.extend(x_test)\n",
    "    x_train = x_all[0:ntrain]\n",
    "    x_train0 = x_all[0:ntrain]\n",
    "    x_test0 = x_all[ntrain:]\n",
    "    \n",
    "    size = 100\n",
    "    model_dm = gensim.models.Doc2Vec(dm=0,min_count=5, window=5, size=size, sample=1e-3, negative=5, workers=3)\n",
    "    model_dm.build_vocab(x_all)\n",
    "    \n",
    "    for i in range(20):\n",
    "        random.shuffle(x_all)\n",
    "        model_dm.train(x_all,total_examples=(ntrain+ntest),epochs=1)\n",
    "    \n",
    "    usei = [3]\n",
    "    usei.extend(list(range(9,17)))\n",
    "    \n",
    "    trainx = getVecs(model_dm, x_train0, size)\n",
    "    trainx = np.hstack((trainx,np.reshape(np.array(train.iloc[:,usei]),[train.shape[0],len(usei)])))\n",
    "    testx = getVecs(model_dm, x_test0, size)\n",
    "    testx = np.hstack((testx,np.reshape(np.array(test.iloc[:,usei]),[test.shape[0],len(usei)])))\n",
    "    \n",
    "    ytrain = np.array(train['stars'])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,input_shape=(1,109),dropout=0.1))\n",
    "    model.add(Dense(units=3,activation=\"sigmoid\"))\n",
    "    model.add(Dense(units=1,activation=\"linear\"))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    model.fit(trainx.reshape(ntrain,1,109), ytrain, validation_split=0.3,epochs=5, batch_size=50)\n",
    "    test0 = testx.reshape(ntest,1,109)\n",
    "    predi = model.predict(test0, batch_size=50)\n",
    "    predi = predi.reshape(ntest,)\n",
    "    \n",
    "\n",
    "    y_pred = np.append(y_pred,predi)\n",
    "    \n",
    "        \n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv('pre80w1005.csv', index = False,encoding='utf-8')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
