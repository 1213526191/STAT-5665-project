library(tidyverse)
dat <- read_csv("../data/data_final.csv")
dat
library(caret)
install.packages("caret")
library(caret)
cv <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)
cv <- createFolds(dat, k = 5, list = TRUE, returnTrain = FALSE)
cv
dat
?createFolds
cv <- createFolds(c(1:100), k = 5, list = TRUE, returnTrain = FALSE)
cv
N <- nrow(dat)
cv <- createFolds(N, k = 5, list = TRUE, returnTrain = FALSE)
cv
cv <- createFolds(c(1:N), k = 5, list = TRUE, returnTrain = FALSE)
cv
names(cv)[1]
cv[1]
length(cv[1])
dim(cv[1])
dat[cv[1],]
as.vector(cv[1])
length(as.vector(cv[1]))
cv[2]
cv[[1]]
dat[cv[[1]],]
X <- dat[,2:6]
y <- dat[,7]
X_train <- X[cv[[i]]]
i = 1
X_train <- X[cv[[i]]]
X_train <- X[cv[[i]],]
X_train <- X[-cv[[i]],]
y_train <- y[-cv[[i]],]
X_test <- X[cv[[i]],]
y_test <- y[cv[[i]],]
dim(X_train)
dim(X_test)
?lm
model <- lm(y_train~X_train)
y_train
X <- as.matrix(dat[,2:6])
y <- as.matrix(dat[,7])
X_train <- X[-cv[[i]],]
y_train <- y[-cv[[i]],]
X_test <- X[cv[[i]],]
y_test <- y[cv[[i]],]
model <- lm(y_train~X_train)
model
?predict
y_fit <- predict(model, X_test)
X <- as.data.frame(dat[,2:6])
y <- as.data.frame(dat[,7])
X_train <- X[-cv[[i]],]
y_train <- y[-cv[[i]],]
X_test <- X[cv[[i]],]
y_test <- y[cv[[i]],]
model <- lm(y_train~X_train)
X_train
type(X_train)
class(X_train)
model <- lm(y_train~X_train)
X_train
X <- dat[,2:6]
y <- dat[,7]
cv <- createFolds(c(1:N), k = 5, list = TRUE, returnTrain = FALSE)
i = 1
X_train <- X[-cv[[i]],]
y_train <- y[-cv[[i]],]
X_test <- X[cv[[i]],]
y_test <- y[cv[[i]],]
model <- lm(y_train~X_train)
y_train
dat
y_train
X_train
?lm
train <- X[-cv[[i]],2:7]
train <- dat[-cv[[i]],2:7]
train <- dat[-cv[[i]],2:7]
test <- dat[cv[[i]],2:7]
train
model <- lm(stars~S1+S2+S3+S4+S5)
model <- lm(stars~S1+S2+S3+S4+S5, train)
test
y_fit <- predict(model, test[,1:5])
y_fit
sum((y_fit-test[,6])^2)/length(y_fit)
sse <- 0
for(i in 1:5){
train <- dat[-cv[[i]],2:7]
test <- dat[cv[[i]],2:7]
model <- lm(stars~S1+S2+S3+S4+S5, train)
y_fit <- predict(model, test[,1:5])
sse <- sse + sum((y_fit-test[,6])^2)
}
sse/nrow(dat)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
linshi <- read_csv("../data/pos_neg.csv")
linshi
data_ori = read_csv("../../data/random100000.csv")
data_ori = read_csv("../data/random100000.csv")
data_ori
?top_n
linshi %>%
top_n(V1, 10)
linshi
linshi %>%
top_n(10, V!)
linshi %>%
top_n(10, V1)
df <- data.frame(x = c(10, 4, 1, 6, 3, 1, 1))
df %>% top_n(2)
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
t1 = Sys.time()
data_tidy <- data_df %>%
unnest_tokens(word, text)
t2 = Sys.time()
t2-t1
linshi %>%
filter(word == "poisoning")
t1 = Sys.time()
data_tidy_unique <- data_tidy %>%
distinct(line, word, stars)
t2 = Sys.time()
t2-t1
data_tidy_unique
data_tidy_unique %>%
filter(word == "poisoning")
linshi2 <- data_tidy_unique %>%
filter(word == "poisoning")
linshi %>%
top_n(10, V1)
linshi2 <- data_tidy_unique %>%
filter(word == "notapologize") %>%
group_by(stars) %>%
summarise(n = n())
linshi2
data_tidy_unique %>%
group_by(stars) %>%
summarise(n = n())
zongshu <- data_tidy_unique %>%
group_by(stars) %>%
summarise(n = n())
zongshu
linshi2
linshi2$n/zongshu$n
linshi %>%
top_n(10, V1)
linshi2 <- data_tidy_unique %>%
filter(word == "poisoning") %>%
group_by(stars) %>%
summarise(n = n())
linshi2
zongshu <- data_tidy_unique %>%
group_by(stars) %>%
summarise(n = n())
linshi2$n/zongshu$n
linshi2 <- data_tidy_unique %>%
filter(word == "poisoning") %>%
group_by(stars) %>%
summarise(n = n())
linshi %>%
filter(word == "poisoning")
linshi %>%
top_n(10, V1)
data_tidy_unique %>%
filter(word == "worst") %>%
group_by(stars) %>%
summarise(n = n())
linshi2 <- data_tidy_unique %>%
filter(word == "worst") %>%
group_by(stars) %>%
summarise(n = n())
zongshu <- data_tidy_unique %>%
group_by(stars) %>%
summarise(n = n())
linshi2$n/zongshu$n
linshi %>%
filter(word == "worst")
data_tidy_unique %>%
filter(word == "worst") %>%
group_by(stars) %>%
summarise(n = n())
linshi2$n/zongshu$n
linshi
linshi %>%
filter(word == "worst")
linshi %>%
top_n(10, V5)
linshi2 <- data_tidy_unique %>%
filter(word == "notregret") %>%
group_by(stars) %>%
summarise(n = n())
linshi2
linshi %>%
filter(word == "notregret")
linshi2$n/zongshu$n
linshi %>%
filter(word == "notregret")
linshi %>%
filter(word == "and")
linshi2 <- data_tidy_unique %>%
filter(word == "and") %>%
group_by(stars) %>%
summarise(n = n())
linshi2
linshi2$n/zongshu$n
linshi %>%
filter(word == "and")
linshi
linshi %>%
top_n(100, V5)
linshi %>%
top_n(100, V5) %>%
select(word, V5)
linshi
linshi %>%
top_n(100, V5) %>%
select(word, V5)
linshi3 <- linshi %>%
top_n(100, V5) %>%
select(word, V5)
getwd()
write_csv(linshi3, "../data/pos.csv")
linshi3 <- linshi %>%
top_n(100, V1) %>%
select(word, V1)
write_csv(linshi3, "../data/neg.csv")
linshi3 <- linshi %>%
top_n(100, V5) %>%
select(word, V5)
linshi3
linshi %>%
top_n(10, V5)
data_tidy_unique %>%
filter(word == "refund")
data_ori
data_ori$text[843]
data_tidy_unique %>%
filter(word == "refund")
data_ori$text[1298]
data_ori$text[4009]
data_tidy_unique %>%
filter(word == "die")
data_ori$text[36]
data_ori$text[616]
data_ori$text[906]
